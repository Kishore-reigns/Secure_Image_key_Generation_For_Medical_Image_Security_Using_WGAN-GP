{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"executionInfo":{"elapsed":312,"status":"error","timestamp":1743581474218,"user":{"displayName":"Maanasa Prathap","userId":"05686310842676992245"},"user_tz":-330},"id":"a_FSHBYP3QJl","outputId":"6b2965f7-786b-424c-950b-86bdde718975"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/CIP/Transformation_zip.zip'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-d8391efad03a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdrive_checkpoint_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/checkpoints/deepkeygen_checkpoint.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_zip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_extract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CIP/Transformation_zip.zip'"]}],"source":["import zipfile\n","import os\n","\n","# kishresun2016@gmail.com -> /content/drive/MyDrive/Sem6/CIP_Team6_2025/Transformation_zip.zip\n","# kishreigns@gamil.com -> /content/drive/MyDrive/Transformation_zip.zip\n","# malarvannanm11@gmail.com -> /content/drive/MyDrive/Transformation_zip.zip\n","# maanasa -> /content/drive/MyDrive/CIP/Transformation.zip\n","#maanasa ->\n","trans_zip_path = \"/content/drive/MyDrive/CIP/Transformation_zip.zip\" # /content/drive/MyDrive/AWS NM/Transformation_zip.zip\n","source_zip_path = \"/content/drive/MyDrive/CIP/source_zip.zip\" #copy path of source domain from cip folder\n","trans_extract_path = \"/content/transformation\"\n","source_extract_path = \"/content/source\"\n","# /content/drive/MyDrive/checkpoints/deepkeygen_checkpoint.pth\n","drive_checkpoint_link = \"/content/drive/MyDrive/checkpoints/deepkeygen_checkpoint.pth\"\n","\n","with zipfile.ZipFile(trans_zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(trans_extract_path)\n","\n","print(f\"Transformation domain extracted successfully: {trans_extract_path}\")\n","\n","with zipfile.ZipFile(source_zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(source_extract_path)\n","print(f\"Souce domain extracted successfully: {source_extract_path}\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"Oa23CbHIKxwK","outputId":"f405b62e-a0d9-480e-baef-b95d23c9505f","executionInfo":{"status":"error","timestamp":1743581500637,"user_tz":-330,"elapsed":18249,"user":{"displayName":"Maanasa Prathap","userId":"05686310842676992245"}}},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"2mYOHI_k48cE","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"8aac1333-1ce9-4cb8-b906-566c12a0b47d","executionInfo":{"status":"error","timestamp":1743581420923,"user_tz":-330,"elapsed":37138,"user":{"displayName":"Maanasa Prathap","userId":"05686310842676992245"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[+] Current working directory: /content\n","[+] Using device: xla:0\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/source'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-50679982a618>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     ])\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0msource_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mtransform_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/source'"]}],"source":["import torch_xla\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, ConcatDataset , Dataset\n","from torchvision import transforms, datasets, utils\n","from PIL import Image\n","import os\n","import kagglehub\n","import torch.autograd as autograd\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.parallel_loader as pl\n","\n","import torch.nn.functional as F\n","import csv\n","# Reduce batch size to save memory\n","batch_size = 4  # Adjusted from 8\n","\n","# Move data to TPU-efficient loader\n","#source_loader = pl.MpDeviceLoader(\n"," #   DataLoader(source_dataset, batch_size=batch_size, shuffle=True), xm.xla_device()\n","#)\n","#transform_loader = pl.MpDeviceLoader(\n","#    DataLoader(transform_dataset, batch_size=batch_size, shuffle=True), xm.xla_device()\n","#)\n","\n","# Adjust training function to include xm.mark_step()\n","def train_deepkeygen(generator, critic, source_loader, transform_loader, num_epochs, lr, device):\n","    optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.9))\n","    optimizer_d = optim.Adam(critic.parameters(), lr=lr, betas=(0.5, 0.9))\n","    lambda_gp = 10\n","    critic_iterations = 5\n","\n","    start_epoch = load_checkpoint(generator, critic, optimizer_g, optimizer_d)\n","    csv_path = \"/content/drive/MyDrive/metrices/metrices.csv\"\n","    #/content/drive/MyDrive/metrices/metrices.csv\n","    #/content/drive/MyDrive/Sem6/CIP_Team6_2025/WGAN_GP_working/metrices.csv\n","    if not os.path.exists(csv_path):\n","        with open(csv_path, \"w\", newline=\"\") as file:\n","            writer = csv.writer(file)\n","            writer.writerow([\"Epoch\", \"Generator Loss\", \"Critic Loss\", \"Wasserstein Distance\", \"Gradient Penalty\", \"D_real\", \"D_fake\", \"Gen_Acc\", \"Critic_Acc\"])\n","\n","    for epoch in range(start_epoch, num_epochs):\n","        print(f\"Epoch: {epoch + 1}/{num_epochs}\", flush=True)\n","        total_gen_correct = 0\n","        total_critic_correct = 0\n","        total_samples = 0\n","        for source_batch, transform_batch in zip(source_loader, transform_loader):\n","            source_imgs, _ = source_batch  # Extract images, ignore labels\n","            transform_imgs, _ = transform_batch  # Extract images, ignore labels\n","\n","            source_imgs = source_imgs.to(device)\n","            transform_imgs = transform_imgs.to(device)\n","\n","            for _ in range(critic_iterations):\n","                fake_imgs = generator(source_imgs).detach()\n","                real_scores = critic(transform_imgs)\n","                fake_scores = critic(fake_imgs)\n","\n","                real_loss = real_scores.mean()\n","                fake_loss = fake_scores.mean()\n","                gp = compute_gradient_penalty(critic, transform_imgs, fake_imgs, device)\n","                critic_loss = fake_loss - real_loss + lambda_gp * gp\n","\n","                optimizer_d.zero_grad()\n","                critic_loss.backward()\n","                xm.optimizer_step(optimizer_d)\n","                xm.mark_step()  # Free TPU memory\n","\n","                total_samples += real_scores.size(0) + fake_scores.size(0)\n","                total_critic_correct += (real_scores > 0).sum().item() + (fake_scores < 0).sum().item()\n","\n","            fake_imgs = generator(source_imgs)\n","            fake_scores = critic(fake_imgs)\n","            generator_loss = -fake_scores.mean()\n","\n","            optimizer_g.zero_grad()\n","            generator_loss.backward()\n","            xm.optimizer_step(optimizer_g)\n","            xm.mark_step()  # Free TPU memory\n","\n","            total_gen_correct += (fake_scores > 0).sum().item()\n","\n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss D: {critic_loss.item()}, Loss G: {generator_loss.item()}\", flush=True)\n","        gen_acc = (total_gen_correct / total_samples) * 100\n","        critic_acc = (total_critic_correct / total_samples) * 100\n","        wasserstein_distance = real_loss.item() - fake_loss.item()\n","\n","        with open(csv_path, \"a\", newline=\"\") as file:\n","            writer = csv.writer(file)\n","            writer.writerow([epoch+1, generator_loss.item(), critic_loss.item(), wasserstein_distance, gp.item(), real_loss.item(), fake_loss.item(), gen_acc, critic_acc])\n","\n","        if (epoch + 1) % 3 == 0:\n","            save_checkpoint(generator, critic, optimizer_g, optimizer_d, epoch)\n","        sample_image, _ = next(iter(source_loader))  # Extract one batch\n","        sample_image = sample_image[:1]  # Select only one image (batch size 1)\n","        save_generated_images(generator, epoch, device, sample_image)\n","\n","    print(\"[+] Training ended\", flush=True)\n","\n","\n","\n","data = []\n","drive_checkpoint_link = \"/content/drive/MyDrive/checkpoints/deepkeygen_checkpoint.pth\"\n","# /checkpoints/deepkeygen_checkpoint.pth\n","#/content/drive/MyDrive/Sem6/CIP_Team6_2025/WGAN_GP_working/deepkeygen_checkpoint.pth\n","\n","# Function to download multiple datasets\n","def download_datasets(dataset_list):\n","    dataset_dirs = [kagglehub.dataset_download(dataset) for dataset in dataset_list]\n","    return dataset_dirs\n","\n","# Function to load multiple datasets into a single DataLoader\n","def load_multiple_datasets(data_dirs, transform, batch_size):\n","    datasets_list = [datasets.ImageFolder(data_dir, transform=transform) for data_dir in data_dirs]\n","    combined_dataset = ConcatDataset(datasets_list)\n","    return DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)\n","\n","def save_checkpoint(generator, critic, optimizer_g, optimizer_d, epoch, filepath=drive_checkpoint_link):\n","    checkpoint = {\n","        'epoch': epoch,\n","        'generator_state_dict': generator.state_dict(),\n","        'critic_state_dict': critic.state_dict(),\n","        'optimizer_g_state_dict': optimizer_g.state_dict(),\n","        'optimizer_d_state_dict': optimizer_d.state_dict()\n","    }\n","    torch.save(checkpoint, filepath)\n","    print(f\"[+]Checkpoint saved at epoch {epoch+1}\")\n","\n","def load_checkpoint(generator, critic, optimizer_g, optimizer_d, filepath=drive_checkpoint_link, device=None):\n","    if os.path.exists(filepath) and os.path.getsize(filepath) > 0: # Check if file exists and has content\n","        try:\n","            checkpoint = torch.load(filepath, map_location=device)\n","            generator.load_state_dict(checkpoint['generator_state_dict'], strict=False)\n","            critic.load_state_dict(checkpoint['critic_state_dict'], strict=False)\n","            optimizer_g.load_state_dict(checkpoint['optimizer_g_state_dict'])\n","            optimizer_d.load_state_dict(checkpoint['optimizer_d_state_dict'])\n","            start_epoch = checkpoint['epoch'] + 1\n","            print(f\"[+]Resuming training from epoch {start_epoch}\")\n","        except RuntimeError as e:\n","            print(f\"[-]Error loading checkpoint: {e}\") # Print error message if loading fails\n","            start_epoch = 0 # Start from epoch 0 if loading fails\n","            print(\"[-]Starting training from scratch due to checkpoint loading error.\")\n","    else:\n","        start_epoch = 0\n","        print(\"[!]No checkpoint found, starting training from scratch.\")\n","\n","    return start_epoch\n","\n","\n","# class PairedMedicalDataset(Dataset):\n","#     def __init__(self, source_dir, transform_dir, transform):\n","#         self.source_images = sorted(os.listdir(source_dir))\n","#         self.transform_images = sorted(os.listdir(transform_dir))\n","#         self.source_dir = source_dir\n","#         self.transform_dir = transform_dir\n","#         self.transform = transform\n","\n","#     def __len__(self):\n","#         return len(self.source_images)\n","\n","#     def __getitem__(self, idx):\n","#         source_path = os.path.join(self.source_dir, self.source_images[idx])\n","#         transform_path = os.path.join(self.transform_dir, self.transform_images[idx])\n","\n","#         source_img = Image.open(source_path).convert(\"RGB\")\n","#         transform_img = Image.open(transform_path).convert(\"RGB\")\n","\n","#         source_img = self.transform(source_img)\n","#         transform_img = self.transform(transform_img)\n","\n","#         return source_img, transform_img\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels):\n","        super(ResidualBlock, self).__init__()\n","        self.block = nn.Sequential(\n","            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.InstanceNorm2d(in_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.InstanceNorm2d(in_channels)\n","        )\n","\n","    def forward(self, x):\n","        return x + self.block(x)  # Residual Connection\n","\n","\n","# Generator Network (G)\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","\n","        # Encoder (Downsampling)\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3, bias=False),\n","            nn.InstanceNorm2d(64),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False),\n","            nn.InstanceNorm2d(128),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, bias=False),\n","            nn.InstanceNorm2d(256),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        # Bottleneck (Residual Blocks)\n","        self.res_blocks = nn.Sequential(*[ResidualBlock(256) for _ in range(6)])\n","\n","        # Decoder (Upsampling)\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n","            nn.InstanceNorm2d(128),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n","            nn.InstanceNorm2d(64),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(64, 3, kernel_size=7, stride=1, padding=3, bias=False),\n","            nn.Tanh()  # Output in range [-1,1]\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.res_blocks(x)\n","        x = self.decoder(x)\n","        return x\n","\n","\n","# Critic (Discriminator) Network (D)\n","class Critic(nn.Module):\n","    def __init__(self):\n","        super(Critic, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n","            nn.InstanceNorm2d(128),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n","            nn.InstanceNorm2d(256),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1, bias=False),\n","            nn.InstanceNorm2d(512),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1, bias=False),\n","            nn.Sigmoid()  # Probability output\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x).view(-1)\n","\n","def compute_gradient_penalty(critic, real_samples, fake_samples, device):\n","    min_batch_size = min(real_samples.size(0), fake_samples.size(0))\n","    real_samples = real_samples[:min_batch_size]\n","    fake_samples = fake_samples[:min_batch_size]\n","\n","    if real_samples.shape != fake_samples.shape:\n","      print(f\"Shape mismatch: real_samples: {real_samples.shape}, fake_samples: {fake_samples.shape}\")\n","\n","    # Create random alpha values for interpolation\n","    alpha = torch.rand(real_samples.shape[0], 1, 1, 1, device=device)  # Random alpha for each image in the batch\n","\n","    # Expand alpha to match the spatial dimensions of the image (8, 3, 256, 256)\n","    alpha = alpha.view(real_samples.shape[0], 1, 1, 1).expand_as(real_samples)\n","\n","\n","    # Interpolate between real and fake samples\n","    interpolates = alpha * real_samples + (1 - alpha) * fake_samples\n","    interpolates.requires_grad_(True)\n","\n","    # Pass the interpolates through the critic\n","    critic_interpolates = critic(interpolates)\n","\n","    # Compute gradients of the critic's output w.r.t. interpolates\n","    grad_outputs = torch.ones_like(critic_interpolates, device=device)\n","\n","    gradients = torch.autograd.grad(\n","        outputs=critic_interpolates,\n","        inputs=interpolates,\n","        grad_outputs=grad_outputs,\n","        create_graph=True,\n","        retain_graph=True,\n","        only_inputs=True\n","    )[0]\n","\n","    # Flatten the gradients and compute the gradient penalty\n","    gradients = gradients.view(gradients.shape[0], -1)\n","    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n","\n","    return gradient_penalty\n","\n","\n","\n","def save_generated_images(generator, epoch, device, sample_image):\n","    generator.eval()\n","    with torch.no_grad():\n","        sample_image = sample_image.to(device)  # Ensure it's on the right device\n","        fake_img = generator(sample_image).squeeze(0)  # Shape: (3, 256, 256)\n","\n","        image_dir = \"/content/drive/MyDrive/CIP_Team6_2025/WGAN_GP_working/extraSource/generated_images\"\n","        os.makedirs(image_dir, exist_ok=True)\n","        image_path = f\"{image_dir}/epoch_{epoch}.png\"\n","        #/content/drive/MyDrive/Sem6/CIP_Team6_2025/WGAN_GP_working/Images\n","        #generated_images/epoch_{epoch}.png\n","\n","        # Save image with correct size\n","        utils.save_image(fake_img, image_path, normalize=True)\n","\n","    generator.train()\n","\n","\n","\n","# Main script\n","if __name__ == \"__main__\":\n","    print(f\"[+] Current working directory: {os.getcwd()}\")\n","\n","    device = xm.xla_device()  # Use TPU device\n","    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n","    #device = torch.device(\"cuda\")\n","    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n","    print(f\"[+] Using device: {device}\")\n","\n","    #csvpath = \"/content/loss.csv\"\n","\n","    #source_datasets = [\"raddar/tuberculosis-chest-xrays-montgomery\", \"masoudnickparvar/brain-tumor-mri-dataset\"]\n","    #source_data_dirs = download_datasets(source_datasets)  # Download datasets from Kaggle\n","\n","    # **Define Paths for Source & Transformed Data**\n","    source_dir = \"/content/source\"  # Directory containing original medical images\n","    transform_dir = \"/content/transformation\"  # Directory containing transformed keys\n","\n","    # **Load Datasets**\n","    batch_size = 8\n","    num_epochs = 250\n","    lr = 0.0002\n","    transform = transforms.Compose([\n","        transforms.Resize((256, 256)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,))\n","    ])\n","    source_dataset = datasets.ImageFolder(source_dir, transform=transform)\n","    transform_dataset = datasets.ImageFolder(transform_dir, transform=transform)\n","\n","    # **Create Data Loaders**\n","    source_loader = DataLoader(source_dataset, batch_size=batch_size, shuffle=True)\n","    transform_loader = DataLoader(transform_dataset, batch_size=batch_size, shuffle=True)\n","\n","    print(\"[+] Datasets loaded successfully!\")\n","\n","\n","    generator = Generator().to(device)\n","    critic = Critic().to(device)\n","\n","    print(\"[+] Training begins\")\n","    train_deepkeygen(generator, critic, source_loader, transform_loader, num_epochs, lr, device)\n","    print(\"[+] Training ended\")\n","\n","\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}